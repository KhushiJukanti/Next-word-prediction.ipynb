{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "Eukpevdk6huH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lexicon = {}\n",
        "\n",
        "def update_lexicon(current : str, next_word : str) -> None:\n",
        "    # Add the input word to the lexicon if it in there yet.\n",
        "    if current not in lexicon:\n",
        "        lexicon.update({current: {next_word: 1} })\n",
        "        return\n",
        "\n",
        "    # Recieve te probabilties of the input word.\n",
        "    options = lexicon[current]\n",
        "\n",
        "    # Check if the output word is in the propability list.\n",
        "    if next_word not in options:\n",
        "        options.update({next_word : 1})\n",
        "    else:\n",
        "        options.update({next_word : options[next_word] + 1})\n",
        "\n",
        "    # Update the lexicon\n",
        "    lexicon[current] = options"
      ],
      "metadata": {
        "id": "mmDk-8L70NgA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "1VddLJ9e6ssM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/dataset.txt', 'r', encoding ='ISO-8859-1') as dataset:\n",
        "    for line in dataset:\n",
        "        words = line.strip().split(' ')\n",
        "        for i in range(len(words) - 1):\n",
        "            update_lexicon(words[i], words[i+1])"
      ],
      "metadata": {
        "id": "l2gE4O0D3FPH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model | Predicting the next Word**"
      ],
      "metadata": {
        "id": "Yzz37KgW6zkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word, transition in lexicon.items():\n",
        "    transition = dict((key, value / sum(transition.values())) for key, value in transition.items())\n",
        "    lexicon[word] = transition\n",
        "\n",
        "line = input('> ')\n",
        "word = line.strip().split(' ')[-1]\n",
        "if word not in lexicon:\n",
        "    print('Word not found')\n",
        "else:\n",
        "    options = lexicon[word]\n",
        "    predicted = np.random.choice(list(options.keys()), p=list(options.values()))\n",
        "    print(line + ' ' + predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i0gogEg3VAg",
        "outputId": "a844c25b-a726-4680-d9f1-6b7353710434"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> I LOVE YOU!\n",
            "I LOVE YOU! Khushi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BcZJs98R3z-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}